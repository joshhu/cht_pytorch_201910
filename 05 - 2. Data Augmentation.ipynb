{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import Augmentor\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import glob\n",
    "\n",
    "def balance_dataset(augment_dir):\n",
    "    \n",
    "    '''\n",
    "    Create train folder from input augment folder\n",
    "    '''\n",
    "    \n",
    "    root_dir = os.path.dirname(augment_dir)\n",
    "    train_dir = os.path.join(root_dir, 'train')\n",
    "    pathlib.Path(train_dir).mkdir(parents=True, exist_ok=True) \n",
    "    augment_ds = datasets.ImageFolder(augment_dir)\n",
    "\n",
    "    for image_folder in augment_ds.classes:\n",
    "        full_image_folder = os.path.join(train_dir, image_folder)\n",
    "        pathlib.Path(full_image_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Counting numbers of each class\n",
    "    '''\n",
    "    \n",
    "    target = torch.tensor(augment_ds.targets)\n",
    "    class_sample_count = torch.tensor([(target == t).sum() \n",
    "                                       for t in torch.unique(target, sorted=True)])\n",
    "    MAX = max(class_sample_count)\n",
    "    sizes = torch.tensor([(MAX-size) for size in class_sample_count])\n",
    "    print(sizes)\n",
    "\n",
    "    '''\n",
    "    Starting augmentation for each class\n",
    "    '''\n",
    "    \n",
    "    for i, category in enumerate(augment_ds.classes):\n",
    "        \n",
    "        img_folder = os.path.join(augment_dir, category)\n",
    "        output_folder = os.path.join(img_folder, 'output')\n",
    "        # augment_images_folder = os.path.join(augment_dir, category)\n",
    "        \n",
    "        shutil.rmtree(output_folder, ignore_errors=True)\n",
    "        \n",
    "        p = Augmentor.Pipeline(img_folder)\n",
    "        p.shear(probability=0.8, max_shear_left=3, max_shear_right=3)\n",
    "        p.rotate(probability=1, max_left_rotation=3, max_right_rotation=3)\n",
    "        p.flip_top_bottom(probability=0.7)\n",
    "        \n",
    "        if sizes[i] != 0:\n",
    "            p.sample(sizes[i], multi_threaded=False)\n",
    "            #p.sample(100, multi_threaded=False)\n",
    "        \n",
    "        '''\n",
    "        Copy original and augmented files to train folders        \n",
    "        '''\n",
    "        dest = os.path.join(train_dir, category)\n",
    "        \n",
    "        for f in glob.glob(img_folder+\"/*.jpg\"):\n",
    "            shutil.copy2(f, dest)\n",
    "            \n",
    "        for f in glob.glob(output_folder+\"/*.jpg\"):\n",
    "            shutil.copy2(f, dest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([148, 291,   0, 354])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing G3GG63-04B3_DefectReview_000005.jpg:  31%|███       | 46/148 [00:00<00:00, 221.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 4019 image(s) found.\n",
      "Output directory set to ./dstest/augment/NG1/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing G3GG63-16C4_DefectReview_000041.jpg: 100%|██████████| 148/148 [00:00<00:00, 283.06 Samples/s]\n",
      "Processing G3GG55-14G2_DefectReview_000022.jpg:  18%|█▊        | 52/291 [00:00<00:00, 309.17 Samples/s]                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3876 image(s) found.\n",
      "Output directory set to ./dstest/augment/NG2/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing G3GG55-04D7_DefectReview_000019.jpg: 100%|██████████| 291/291 [00:01<00:00, 263.45 Samples/s]                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 4167 image(s) found.\n",
      "Output directory set to ./dstest/augment/NG3/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing FNK205-18D5_DefectReview_000203.jpg:  16%|█▌        | 57/354 [00:00<00:00, 319.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3813 image(s) found.\n",
      "Output directory set to ./dstest/augment/OK/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing FNV595-19H1_DefectReview_000009.jpg: 100%|██████████| 354/354 [00:01<00:00, 302.97 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "destdir = \"./dstest/\"\n",
    "balance_dataset(os.path.join(destdir, 'augment'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
